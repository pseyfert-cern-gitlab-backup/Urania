{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks \n",
    "\n",
    "Neural networks inside [hep_ml](github.com/arogozhnikov/hep_ml) are very simple, but flexible. They are using [theano](http://deeplearning.net/software/theano/) library.\n",
    "\n",
    "**hep_ml.nnet** also provides tools to optimize any continuos expression as decision function (see below). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset\n",
    "downloading dataset from UCI and splitting it into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 0: cd: toy_datasets: No such file or directory\n",
      "Файл «../data/MiniBooNE_PID.txt» уже существует; не загружается.\n"
     ]
    }
   ],
   "source": [
    "!cd toy_datasets; wget -O ../data/MiniBooNE_PID.txt -nc MiniBooNE_PID.txt https://archive.ics.uci.edu/ml/machine-learning-databases/00199/MiniBooNE_PID.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = pandas.read_csv('../data/MiniBooNE_PID.txt', sep='\\s*', skiprows=[0], header=None, engine='python')\n",
    "labels = pandas.read_csv('../data/MiniBooNE_PID.txt', sep=' ', nrows=1, header=None)\n",
    "labels = [1] * labels[1].values[0] + [0] * labels[2].values[0]\n",
    "data.columns = ['feature_{}'.format(key) for key in data.columns]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of training network\n",
    "Training multilayer perceptron with one hidden layer with 5 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(epochs=500, layers=[5], loss='log_loss', random_state=None,\n",
       "       scaler='standard', trainer='irprop-', trainer_parameters=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hep_ml.nnet import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = MLPClassifier(layers=[5], epochs=500)\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.971250859023\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(test_data)\n",
    "print 'Test quality:', roc_auc_score(test_labels, proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train quality: 0.971777980506\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(train_data)\n",
    "print 'Train quality:', roc_auc_score(train_labels, proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating own neural network\n",
    "\n",
    "To create own neural network, one should provide activation function and define parameters of network.\n",
    "\n",
    "You are not limited here to any kind of structure in this function, **hep_ml.nnet** will consider this as a black box for optimization.\n",
    "\n",
    "Simplest way is to override `prepare` method of `AbstractNeuralNetworkClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hep_ml.nnet import AbstractNeuralNetworkClassifier\n",
    "from theano import tensor as T\n",
    "\n",
    "class SimpleNeuralNetwork(AbstractNeuralNetworkClassifier):\n",
    "    def prepare(self):\n",
    "        # getting number of layers in input, hidden, output layers\n",
    "        # note that we support only one hidden layer here\n",
    "        n1, n2, n3 = self.layers_\n",
    "        \n",
    "        # creating parameters of neural network\n",
    "        W1 = self._create_matrix_parameter('W1', n1, n2)\n",
    "        W2 = self._create_matrix_parameter('W2', n2, n3)\n",
    "        \n",
    "        # defining activation function\n",
    "        def activation(input):\n",
    "            first = T.nnet.sigmoid(T.dot(input, W1))\n",
    "            return T.dot(first, W2)\n",
    "\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.967173363583\n"
     ]
    }
   ],
   "source": [
    "clf = SimpleNeuralNetwork(layers=[5], epochs=500)\n",
    "clf.fit(train_data, train_labels)\n",
    "print 'Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using specific neural network\n",
    "this NN has one hidden layer, but it is quite strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.972384121561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "from hep_ml.nnet import PairwiseNeuralNetwork\n",
    "clf = PairwiseNeuralNetwork(layers=[5], epochs=500)\n",
    "clf.fit(train_data, train_labels)\n",
    "print 'Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating very specific expression estimators\n",
    "We can use **hep_ml.nnet** to optimize any expressions as black-box\n",
    "for simplicity, let's assume we have only three variables: $\\text{var}_1, \\text{var}_2, \\text{var}_3.$\n",
    "\n",
    "And for some physical intuition we are sure that this is good expression to discriminate signal and background:\n",
    "$$\\text{output} = c_1 \\text{var}_1 + c_2 \\log[ \\exp(\\text{var}_2 + \\text{var}_3) + \\exp(c_3)] + c_4 \\dfrac{\\text{var}_3}{\\text{var}_2} + c_5 $$\n",
    "\n",
    "**Note**: I have written some random expression here, in practice it appears from physical intuition (or looking at the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomNeuralNetwork(AbstractNeuralNetworkClassifier):\n",
    "    def prepare(self):\n",
    "        # getting number of layers in input, hidden, output layers\n",
    "        # note that we support only one hidden layer here\n",
    "        n1, n2, n3 = self.layers_        \n",
    "        # checking that we have three variables in input + constant\n",
    "        assert n1 == 3 + 1 \n",
    "        # creating parameters\n",
    "        c1, c2, c3, c4, c5 = self._create_scalar_parameters('c1', 'c2', 'c3', 'c4', 'c5')\n",
    "        \n",
    "        # defining activation function\n",
    "        def activation(input):\n",
    "            v1, v2, v3 = input[:, 0], input[:, 1], input[:, 2]\n",
    "            return c1 * v1 + c2 * T.log(T.exp(v2 + v3) + T.exp(c3)) + c4 * v3 / v2 + c5\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing custom pretransformer\n",
    "very simple `scikit-learn` transformer which will transform each feature uniform to range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from rep.utils import Flattener\n",
    "\n",
    "class Uniformer(BaseEstimator, TransformerMixin):\n",
    "    # leaving only 3 features and flattening each variable\n",
    "    def fit(self, X, y=None):\n",
    "        self.transformers = []\n",
    "        X = numpy.array(X, dtype=float)\n",
    "        for column in range(X.shape[1]):\n",
    "            self.transformers.append(Flattener(X[:, column]))\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = numpy.array(X, dtype=float)\n",
    "        assert X.shape[1] == len(self.transformers)\n",
    "        for column, trans in enumerate(self.transformers):\n",
    "            X[:, column] = trans(X[:, column])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.914575996678\n"
     ]
    }
   ],
   "source": [
    "# selecting three features to train: \n",
    "train_features = train_data.columns[:3]\n",
    "\n",
    "clf = CustomNeuralNetwork(layers=[5], epochs=1000, scaler=Uniformer())\n",
    "clf.fit(train_data[train_features], train_labels)\n",
    "\n",
    "print 'Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data[train_features])[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling neural neworks\n",
    "let's run AdaBoost algorithm over neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=MLPClassifier(epochs=100, layers=[5], loss='log_loss', random_state=None,\n",
       "       scaler=Uniformer(), trainer='irprop-', trainer_parameters=None),\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_nnet = base_estimator=MLPClassifier(layers=[5], scaler=Uniformer())\n",
    "clf = AdaBoostClassifier(base_estimator=base_nnet, n_estimators=10)\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test quality: 0.977154302238\n"
     ]
    }
   ],
   "source": [
    "print 'Test quality:', roc_auc_score(test_labels, clf.predict_proba(test_data)[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
